{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nfrom scipy import ndimage\n# import nibabel as nib\nimport pydicom\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import backend as K\nimport keras_cv\n# import keras_core as keras\nfrom tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import  plot_model ,Sequence\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import VGG16\nimport tensorflow as tf\nfrom tensorflow.python.keras.losses import binary_crossentropy\nimport keras\nfrom keras_cv.models import ResNetBackbone\nfrom tensorflow.keras.utils import custom_object_scope\nimport os\nfrom glob import glob  # for getting list paths of image and labels\nfrom random import choice,sample\nfrom matplotlib import pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-11T11:51:35.743435Z","iopub.execute_input":"2023-10-11T11:51:35.744005Z","iopub.status.idle":"2023-10-11T11:51:50.683700Z","shell.execute_reply.started":"2023-10-11T11:51:35.743960Z","shell.execute_reply":"2023-10-11T11:51:50.682648Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Using TensorFlow backend\n","output_type":"stream"}]},{"cell_type":"code","source":"class Config:\n    image_size = [256,256,256]\n    batch_size = 19\n    base_path = \"/kaggle/input/rsna-2023-abdominal-trauma-detection\"\n    custom_path = \"/kaggle/input/images-for-training-png-rsna2023\"\n    train_images_path = '/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/'\n    data_path=\"/kaggle/input/train4/\"\n    dim = (256,256,256)\n    columns = [\n        [\"bowel_injury\"], [\"extravasation_injury\"],\n        [\"kidney_healthy\", \"kidney_low\", \"kidney_high\"],\n        [\"liver_healthy\", \"liver_low\", \"liver_high\"],\n        [\"spleen_healthy\", \"spleen_low\", \"spleen_high\"],\n    ]\n    epochs = 100\n    SEED = 65\n    AUTO = tf.data.AUTOTUNE\ncfg = Config()\ntf.keras.utils.set_random_seed(seed=cfg.SEED)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.685413Z","iopub.execute_input":"2023-10-11T11:51:50.686367Z","iopub.status.idle":"2023-10-11T11:51:50.696532Z","shell.execute_reply.started":"2023-10-11T11:51:50.686331Z","shell.execute_reply":"2023-10-11T11:51:50.695136Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(f'{cfg.base_path}/train.csv')\n\nbowel_injury = train.loc[train.bowel_injury==1]\nbowel_healthy = train.loc[train.bowel_injury==0].sample(bowel_injury.shape[0], random_state=cfg.SEED)\n\nextra_injury = train.loc[train.extravasation_injury==1]\nextra_healthy = train.loc[train.extravasation_injury ==0].sample(extra_injury.shape[0], random_state=cfg.SEED)\n\nkidney_high = train.loc[train.kidney_high==1]\nkidney_low = train.loc[train.kidney_low==1]\navg = (kidney_high.shape[0] + kidney_low.shape[0])//2\nkidney_healthy = train.loc[train.kidney_healthy==1].sample(avg,random_state=cfg.SEED)\n\nliver_high = train.loc[train.liver_high==1]\nliver_low = train.loc[train.liver_low==1]\navg = (liver_high.shape[0] + liver_low.shape[0])//2 - 1\nliver_healthy = train.loc[train.liver_healthy==1].sample(avg,random_state=cfg.SEED)\n\nspleen_high = train.loc[train.spleen_high==1]\nspleen_low = train.loc[train.spleen_low==1]\navg = (spleen_high.shape[0] + spleen_low.shape[0])//2 - 3\nspleen_healthy = train.loc[train.spleen_healthy==1].sample(avg,random_state=cfg.SEED)\n\nbowel = pd.concat([bowel_healthy,bowel_injury])\nextra = pd.concat([extra_healthy,extra_injury])\nkidney = pd.concat([kidney_healthy,kidney_high,kidney_low])\nliver = pd.concat([liver_healthy,liver_high,liver_low])\nspleen = pd.concat([spleen_healthy,spleen_high,spleen_low])","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.699131Z","iopub.execute_input":"2023-10-11T11:51:50.700204Z","iopub.status.idle":"2023-10-11T11:51:50.757417Z","shell.execute_reply.started":"2023-10-11T11:51:50.700156Z","shell.execute_reply":"2023-10-11T11:51:50.756500Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_sm = pd.read_csv(f'{cfg.base_path}/train_series_meta.csv')\ndef trim_dataset(df,columns):\n    df = df.merge(train_sm,on=[\"patient_id\"], how=\"inner\")\n    df = df.sort_values('aortic_hu', ascending=False).drop_duplicates(subset=['patient_id'])\n    columns = [\"patient_id\",\"series_id\"] + columns\n    df = df[columns]\n    return df\nbowel = trim_dataset(bowel, cfg.columns[0])\nextra = trim_dataset(extra, cfg.columns[1])\nkidney = trim_dataset(kidney, cfg.columns[2])\nliver = trim_dataset(liver, cfg.columns[3])\nspleen = trim_dataset(spleen, cfg.columns[4])","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.759813Z","iopub.execute_input":"2023-10-11T11:51:50.760146Z","iopub.status.idle":"2023-10-11T11:51:50.803305Z","shell.execute_reply.started":"2023-10-11T11:51:50.760116Z","shell.execute_reply":"2023-10-11T11:51:50.802239Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"bowel_train_images, bowel_val_images, bowel_train_labels, bowel_val_labels = train_test_split(bowel[[\"patient_id\",\"series_id\"]],bowel[cfg.columns[0]],random_state=cfg.SEED,test_size=0.125)\nextra_train_images, extra_val_images, extra_train_labels, extra_val_labels = train_test_split(extra[[\"patient_id\",\"series_id\"]],extra[cfg.columns[1]],random_state=cfg.SEED,test_size=0.20)\nkidney_train_images, kidney_val_images, kidney_train_labels, kidney_val_labels = train_test_split(kidney[[\"patient_id\",\"series_id\"]],kidney[cfg.columns[2]],random_state=cfg.SEED,test_size=0.142857)\nliver_train_images, liver_val_images, liver_train_labels, liver_val_labels = train_test_split(liver[[\"patient_id\",\"series_id\"]],liver[cfg.columns[3]],random_state=cfg.SEED,test_size=0.16665)\nspleen_train_images, spleen_val_images, spleen_train_labels, spleen_val_labels = train_test_split(spleen[[\"patient_id\",\"series_id\"]],spleen[cfg.columns[4]],random_state=cfg.SEED,test_size=0.25)\n\nbowel_train_images, bowel_val_images, bowel_train_labels, bowel_val_labels = bowel_train_images.values, bowel_val_images.values, bowel_train_labels.values, bowel_val_labels.values\nextra_train_images, extra_val_images, extra_train_labels, extra_val_labels = extra_train_images.values, extra_val_images.values, extra_train_labels.values, extra_val_labels.values\nkidney_train_images, kidney_val_images, kidney_train_labels, kidney_val_labels = kidney_train_images.values, kidney_val_images.values, kidney_train_labels.values, kidney_val_labels.values\nliver_train_images, liver_val_images, liver_train_labels, liver_val_labels = liver_train_images.values, liver_val_images.values, liver_train_labels.values, liver_val_labels.values\nspleen_train_images, spleen_val_images, spleen_train_labels, spleen_val_labels = spleen_train_images.values, spleen_val_images.values, spleen_train_labels.values, spleen_val_labels.values","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.804791Z","iopub.execute_input":"2023-10-11T11:51:50.805385Z","iopub.status.idle":"2023-10-11T11:51:50.832877Z","shell.execute_reply.started":"2023-10-11T11:51:50.805349Z","shell.execute_reply":"2023-10-11T11:51:50.831858Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pydicom\ndef standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n    \"\"\"\n    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n    \"\"\"\n    # Correct DICOM pixel_array if PixelRepresentation == 1.\n    pixel_array = dcm.pixel_array\n    if dcm.PixelRepresentation == 1:\n        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n        dtype = pixel_array.dtype \n        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n\n    intercept = float(dcm.RescaleIntercept)\n    slope = float(dcm.RescaleSlope)\n    center = int(dcm.WindowCenter)\n    width = int(dcm.WindowWidth)\n    low = center - width / 2\n    high = center + width / 2    \n    \n    pixel_array = (pixel_array * slope) + intercept\n    pixel_array = np.clip(pixel_array, low, high)\n\n    return pixel_array\n\ndef resize_volume(img):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = 128\n    desired_width = 256\n    desired_height = 256\n    # Get current depth\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n    # Compute depth factor\n    depth = current_depth / desired_depth\n    width = current_width / desired_width\n    height = current_height / desired_height\n    depth_factor = 1 / depth\n    width_factor = 1 / width\n    height_factor = 1 / height\n    # Rotate\n    img = ndimage.rotate(img, 90, reshape=False)\n    # Resize across z-axis\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img\n\n\ndef process(patient,study, data_path=\"\"):\n    imgs = {}\n    for f in sorted(glob(data_path + f\"{patient}/{study}/*.dcm\")):\n#         if f == f\"{data_path}3124/5842/514.dcm\":\n#             continue\n            \n        dicom = pydicom.dcmread(f)\n\n        pos_z = dicom[(0x20, 0x32)].value[-1]\n\n        img = standardize_pixel_array(dicom)\n        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n\n        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            img = 1 - img\n        img = tf.image.resize(tf.expand_dims(img,axis=2),size=[256,256])[:,:,0]\n        imgs[pos_z] = img\n        \n    image = []\n    for i, k in enumerate(sorted(imgs.keys())):\n        img = imgs[k]\n        image.append(img)\n    scan = tf.stack(image)\n    scan = resize_volume(scan)\n    return scan","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.834768Z","iopub.execute_input":"2023-10-11T11:51:50.835167Z","iopub.status.idle":"2023-10-11T11:51:50.851648Z","shell.execute_reply.started":"2023-10-11T11:51:50.835131Z","shell.execute_reply":"2023-10-11T11:51:50.850534Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(value).numpy()]))\n\ndef serialize_example(images,labels):\n    feature = {\n        'image': _bytes_feature(images),\n        'labels' : _bytes_feature(labels)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\ndef writeTFR(filename,train_img_meta, val_img_meta, train_img_labels, val_img_labels):\n    \n    train_filename = f\"{filename}_train.tfrecord\"\n    number_train = len(train_img_meta)\n    with tf.io.TFRecordWriter(train_filename) as writer:\n        for i in tqdm(range(number_train)):\n            feature1 = process(train_img_meta[i][0],train_img_meta[i][1],data_path=\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/\")\n            feature2 = train_img_labels[i]\n            example = serialize_example(feature1,feature2)\n            writer.write(example)\n            \n    number_val = len(val_img_meta)\n    val_filename = f\"{filename}_val.tfrecord\"\n    with tf.io.TFRecordWriter(val_filename) as writer:\n        for i in tqdm(range(number_val)):\n            feature1 = process(val_img_meta[i][0],val_img_meta[i][1],data_path=\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/\")\n            feature2 = val_img_labels[i]\n            example = serialize_example(feature1,feature2)\n            writer.write(example)","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.853181Z","iopub.execute_input":"2023-10-11T11:51:50.853790Z","iopub.status.idle":"2023-10-11T11:51:50.868181Z","shell.execute_reply.started":"2023-10-11T11:51:50.853750Z","shell.execute_reply":"2023-10-11T11:51:50.867038Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"writeTFR(\"spleen\",spleen_train_images,spleen_val_images,spleen_train_labels, spleen_val_labels)\nprint(\"spleen done\")","metadata":{"execution":{"iopub.status.busy":"2023-10-11T11:51:50.869901Z","iopub.execute_input":"2023-10-11T11:51:50.870662Z","iopub.status.idle":"2023-10-11T13:31:00.713183Z","shell.execute_reply.started":"2023-10-11T11:51:50.870616Z","shell.execute_reply":"2023-10-11T13:31:00.711198Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 396/396 [1:14:01<00:00, 11.22s/it]\n100%|██████████| 132/132 [25:08<00:00, 11.43s/it]","output_type":"stream"},{"name":"stdout","text":"spleen done\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}